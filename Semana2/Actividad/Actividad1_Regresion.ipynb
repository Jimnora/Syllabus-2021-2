{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce3350f",
   "metadata": {},
   "source": [
    "# Actividad 1: Regresion\n",
    "\n",
    "Esta actividad debe ser completada antes del Viernes de esta semana, a las 20:00 horas. Deberás subir el notebook completo y reportar tu nivel de avance en el cuestionario habilitado para el siding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07bfc19",
   "metadata": {},
   "source": [
    "La meta, por supuesto, es aprender a estimar un modelo de regresión lineal. Comenzemos por cargar datos para armar una regresion. Esta vez nuestros datos son tabulares, pero pandas los puede leer sin mucho problema (están limpios). Los datos corresponden al dataset usado por Francis Galton para estudiar la estatura de las personas (de este ejercicio, publicado en 1886, viene el término 'regresión'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fb81f05d",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 898 entries, 0 to 897\nData columns (total 8 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   family  898 non-null    object \n 1   father  898 non-null    float64\n 2   mother  898 non-null    float64\n 3   gender  898 non-null    object \n 4   height  898 non-null    float64\n 5   kids    898 non-null    int64  \n 6   male    898 non-null    float64\n 7   female  898 non-null    float64\ndtypes: float64(5), int64(1), object(2)\nmemory usage: 56.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "galton = pd.read_table('galton-stata11.tab')\n",
    "galton.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f36ed05",
   "metadata": {},
   "source": [
    "'family' es un identificador asignado a cada familia. 'father' y 'mother' es la estatura de su padre y madre. 'height' es la estatura del hijo (una vez adulto). 'gender', 'male' y 'female' son autoexplicativos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c6f85533",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    family  father  mother gender  height  kids  male  female\n",
       "0        1    78.5    67.0      M    73.2     4   1.0     0.0\n",
       "1        1    78.5    67.0      F    69.2     4   0.0     1.0\n",
       "2        1    78.5    67.0      F    69.0     4   0.0     1.0\n",
       "3        1    78.5    67.0      F    69.0     4   0.0     1.0\n",
       "4        2    75.5    66.5      M    73.5     4   1.0     0.0\n",
       "..     ...     ...     ...    ...     ...   ...   ...     ...\n",
       "893   136A    68.5    65.0      M    68.5     8   1.0     0.0\n",
       "894   136A    68.5    65.0      M    67.7     8   1.0     0.0\n",
       "895   136A    68.5    65.0      F    64.0     8   0.0     1.0\n",
       "896   136A    68.5    65.0      F    63.5     8   0.0     1.0\n",
       "897   136A    68.5    65.0      F    63.0     8   0.0     1.0\n",
       "\n",
       "[898 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>family</th>\n      <th>father</th>\n      <th>mother</th>\n      <th>gender</th>\n      <th>height</th>\n      <th>kids</th>\n      <th>male</th>\n      <th>female</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>78.5</td>\n      <td>67.0</td>\n      <td>M</td>\n      <td>73.2</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>78.5</td>\n      <td>67.0</td>\n      <td>F</td>\n      <td>69.2</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>78.5</td>\n      <td>67.0</td>\n      <td>F</td>\n      <td>69.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>78.5</td>\n      <td>67.0</td>\n      <td>F</td>\n      <td>69.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>75.5</td>\n      <td>66.5</td>\n      <td>M</td>\n      <td>73.5</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>893</th>\n      <td>136A</td>\n      <td>68.5</td>\n      <td>65.0</td>\n      <td>M</td>\n      <td>68.5</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>136A</td>\n      <td>68.5</td>\n      <td>65.0</td>\n      <td>M</td>\n      <td>67.7</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>136A</td>\n      <td>68.5</td>\n      <td>65.0</td>\n      <td>F</td>\n      <td>64.0</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>136A</td>\n      <td>68.5</td>\n      <td>65.0</td>\n      <td>F</td>\n      <td>63.5</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>136A</td>\n      <td>68.5</td>\n      <td>65.0</td>\n      <td>F</td>\n      <td>63.0</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>898 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 223
    }
   ],
   "source": [
    "galton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd101d3",
   "metadata": {},
   "source": [
    "Las alturas están en pulgadas, lo que es horrible. Las pasamos a metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "aab0c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "galton['father'] = 0.0254 * galton['father']\n",
    "galton['mother'] = 0.0254 * galton['mother']\n",
    "galton['height'] = 0.0254 * galton['height']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9a412",
   "metadata": {},
   "source": [
    "### Ajustando una regresión\n",
    "\n",
    "Nota que tenemos que sacar la variable 'family' y la de 'gender', por que no son números. La de gender la tenemos con male/female, y el id de familia no debería aportarnos mucho acá, así que lo sacamos sin cuidado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7ac9abea",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Coeficientes: \n [ 0.39830528  0.32095528 -0.00111299  0.06616632 -0.06616632]\nBeta0: \n 0.477334232240503\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Crea un objeto regresión\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Lo entrenamos usando el dataset de Galton, queremos predecir la altura (height)\n",
    "regr.fit(galton[['father','mother','kids','male','female']], galton['height'])\n",
    "\n",
    "# Imprimimos los coeficientes (los beta). Están en el orden en que están los atributos\n",
    "print('Coeficientes: \\n', regr.coef_)\n",
    "print('Beta0: \\n', regr.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369aa440",
   "metadata": {},
   "source": [
    "Y bueno, ya tenemos una regresión. ¿Qué podemos hacer? podemos, por ejemplo, predecir cuando mediría una niña dada la altura de su papá, de su mamá y cuantos hijos tuvieron sus padres.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a1086463",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   father  mother  kids  male  female\n0       2       2     2     1       0\n1       2       2     2     0       1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.97979571, 1.84746306])"
      ]
     },
     "metadata": {},
     "execution_count": 226
    }
   ],
   "source": [
    "#Diccionario con dos filas, papá y mamá miden dos metros, tienen dos hijos, uno es hombre y otro mujer\n",
    "para_predecir = pd.DataFrame({'father':[2,2],'mother':[2,2],'kids':[2,2],'male':[1,0],'female':[0,1]})\n",
    "print(para_predecir)\n",
    "\n",
    "#ahora le pedimos al modelo de regresión que nos prediga la estatura de los hijos: \n",
    "regr.predict(para_predecir)\n",
    "\n",
    "#el resultado: hijo hombre mediría 1.97, hija mujer 1.84"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a60563",
   "metadata": {},
   "source": [
    "Ahora bien. Hay un campo que está un poco extraño, y es la cantidad de hijos que tiene esta familia. Por qué debería influir la cantidad de hermanos en la altura de una persona? ¿Qué pasa si en vez de predecir el valor de arriba para dos hijos, predecirmos como si la familia tuviera 7 hijos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d0f26d86",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   father  mother  kids  male  female\n0       2       2     7     1       0\n1       2       2     7     0       1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.97423077, 1.84189813])"
      ]
     },
     "metadata": {},
     "execution_count": 227
    }
   ],
   "source": [
    "para_predecir = pd.DataFrame({'father':[2,2],'mother':[2,2],'kids':[7,7],'male':[1,0],'female':[0,1]})\n",
    "print(para_predecir)\n",
    "\n",
    "\n",
    "regr.predict(para_predecir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086a707",
   "metadata": {},
   "source": [
    "El resultado cambia! Esto no hace ningún sentido: ¿cómo va a ser que la altura de las personas dependa de la cantidad de sus hermanos? Algo extraño debe estar pasando. \n",
    "\n",
    "### Ejercicio 1\n",
    "\n",
    "Entrena una regresión que solo tome en cuenta 'father', 'mother', 'male', 'female', y luego una que solo tome en cuenta 'mother', 'male', 'female'. Predice valores como los de arriba, y discute sobre cuál es mejor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "747997a4",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Segundo Modelo\n",
      "\n",
      "Coeficientes: \n",
      " [ 0.40597803  0.32149514  0.06636958 -0.06636958]\n",
      "Beta0: \n",
      " 0.45612648612166606\n",
      "   father  mother  male  female\n",
      "0       2       2     1       0\n",
      "1       2       2     0       1\n",
      "[1.97744239 1.84470323]\n",
      "\n",
      "\n",
      "Tercer Modelo\n",
      "\n",
      "Coeficientes: \n",
      " [ 3.53137126e-01 -3.47042780e+12 -3.47042780e+12]\n",
      "Beta0: \n",
      " 3470427797211.564\n",
      "   mother  male  female\n",
      "0       2     1       0\n",
      "1       2     0       1\n",
      "[1.89111328 1.75927734]\n"
     ]
    }
   ],
   "source": [
    "regr2 = linear_model.LinearRegression()\n",
    "\n",
    "regr2.fit(galton[['father','mother','male','female']], galton['height'])\n",
    "print(\"\\nSegundo Modelo\\n\")\n",
    "print('Coeficientes: \\n', regr2.coef_)\n",
    "print('Beta0: \\n', regr2.intercept_)\n",
    "\n",
    "regr3 = linear_model.LinearRegression()\n",
    "\n",
    "para_predecir2 = pd.DataFrame({'father':[2,2],'mother':[2,2],'male':[1,0],'female':[0,1]})\n",
    "print(para_predecir2)\n",
    "print(regr2.predict(para_predecir2))\n",
    "\n",
    "regr3.fit(galton[['mother','male','female']], galton['height'])\n",
    "print(\"\\n\\nTercer Modelo\\n\")\n",
    "print('Coeficientes: \\n', regr3.coef_)\n",
    "print('Beta0: \\n', regr3.intercept_)\n",
    "\n",
    "para_predecir3 = pd.DataFrame({'mother':[2,2],'male':[1,0],'female':[0,1]})\n",
    "print(para_predecir3)\n",
    "print(regr3.predict(para_predecir3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "Al ver los resultados obtenidos, vemos que la regresion lineal obtenida incluyendo la variable father tiene valores mas similares a los obtenidos anteriormente, con valores aproximados de 1.98 1.84. En cambio, al quitar la variable father estos valores disminuyenen en casi una decima, con valores aproximados de 1.89 1.76. Esto talvez nos indica que la variable father afecta el valor de height de una manera mayor, por lo que seria importante incluirla dentro de la regresion lineal."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "59c8ba39",
   "metadata": {},
   "source": [
    "# Seleccionando mejores modelos\n",
    "\n",
    "Antes de entender qué pasa que nuestro modelo toma en cuenta la cantidad de hermanos a la hora de predecir, veamos algo más general: ¿cómo seleccionar los mejores modelos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac196a56",
   "metadata": {},
   "source": [
    "## Alternativa 1: Mean-squared error (MSE), r^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc7df2",
   "metadata": {},
   "source": [
    "Recordemos que otra forma de ajustar una regresión es encontrar una función que minimiza los cuadrados de los errores: \n",
    "en nuestro caso el error de cada punto se calcula como el valor de height en el dataset menos el valor predicho por la regresión, todo eso al cuadrado:  Si tomamos la media de ese error, llegamos al MSE. Lógicamente, mientras mas chico el MSE, más se ajusta la función a los datos. \n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{1 \\leq i \\leq n} (y_i - \\beta^T\\bar x^i)^2$$\n",
    "\n",
    "El coeficiente r^2 corresponde a la suma de los errores, dividido por la diferencia entre cada punto y su media. \n",
    "\n",
    "$$r^2 = 1 - \\frac{\\sum_{1 \\leq i \\leq n} (y_i - \\beta^T\\bar x^i)^2}{\\sum_{1 \\leq i \\leq n} (y_i - \\bar y)^2},$$\n",
    "\n",
    "donde $$\\bar y = \\frac{\\sum_{1 \\leq i \\leq n} y_i}{n}$$\n",
    "\n",
    "El coeficiente r^2 va desde 1 (cuando la suma de los errores es cero, un modelo que se ajusta perfecto) a 0 (cuando la suma de los errores es igual a la diferencia entre cada punto y su media, el modelo no sirve para nada). \n",
    "\n",
    "Veamos como obtener el MSE, y el coeficiente r^2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "97cbb6d9",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean squared error: 0.002972\nCoeficiente r2: 0.64\n"
     ]
    }
   ],
   "source": [
    "#pedimos la predicción de todos los datos. \n",
    "galton_pred = regr.predict(galton[['father','mother','kids','male','female']])\n",
    "\n",
    "#calculamos el MSE\n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton['height'], galton_pred))\n",
    "\n",
    "#calculamos el r^2\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton['height'], galton_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44a8f2",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "¿Cuál de los tres modelos que has entrenado tiene mejor MSE? ¿mejor r^2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5e41ce3d",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nPrimer Modelo\nMean squared error: 0.002972\nCoeficiente r2: 0.64\n\nSegundo Modelo\nMean squared error: 0.002981\nCoeficiente r2: 0.64\n\nTercer Modelo\nMean squared error: 0.003625\nCoeficiente r2: 0.56\n"
     ]
    }
   ],
   "source": [
    "galton_pred = regr.predict(galton[['father','mother','kids','male','female']])\n",
    "\n",
    "print(\"\\nPrimer Modelo\")\n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton['height'], galton_pred))\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton['height'], galton_pred))\n",
    "\n",
    "galton_pred2 = regr2.predict(galton[['father','mother','male','female']])\n",
    "\n",
    "print(\"\\nSegundo Modelo\")\n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton['height'], galton_pred2))\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton['height'], galton_pred2))\n",
    "\n",
    "galton_pred3 = regr3.predict(galton[['mother','male','female']])\n",
    "\n",
    "print(\"\\nTercer Modelo\")\n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton['height'], galton_pred3))\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton['height'], galton_pred3))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "El primer modelo pareceria tener los mejores valores de MSE y r2, con el segundo modelo teniendo el mismo r2 que el primero, pero con MSE un poco mayor. Como se supuso antes, el tercer modelo empeora respecto a los anteriores, debido al haber retirado la variable father."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "0afc9148",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec89e19a",
   "metadata": {},
   "source": [
    "Si hiciste el **Ejercicio 2**, te estarás preguntando por qué es mejor el modelo que usa la variable 'kids', siendo que no debería tener nada que ver en este caso. \n",
    "\n",
    "La respuesta a este tipo de preguntas muchas veces viene del hecho que los modelos de machine learning terminan aprendiendo *demasiado* los datos, hasta un punto en que se aprovechan de patrones espureos para poder ajustar un poquitito mejor la recta. En este caso, bien puede haber pasado algo así. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b8025",
   "metadata": {},
   "source": [
    "¿Cuál es el problema del overfitting? Que cuando queramos usar nuestro predictor en un ambiente real, los datos quizá no van a respetar esa correlación, y nuestro modelo va a terminar siendo, en la práctica, peor. Una forma bien estándar de asegurarnos que esto no pasa es dividir el set de datos, de forma de calcular el MSE con datos que son distintos a los que se usaron para entrenar.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66123edc",
   "metadata": {},
   "source": [
    "### Alternativa 2:  Train-test split\n",
    "\n",
    "La idea es simple: vamos a ajustar la regresión con menos datos de los que teníamos (digamos un 80% de los datos), y vamos a *reservar* los otros para calcular el MSE y el r^2 con datos realistas, que no se usaron para entrenar al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "aca6dc2e",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "family    718\nfather    718\nmother    718\ngender    718\nheight    718\nkids      718\nmale      718\nfemale    718\ndtype: int64\nfamily    180\nfather    180\nmother    180\ngender    180\nheight    180\nkids      180\nmale      180\nfemale    180\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "galton_train, galton_test = train_test_split(galton, train_size=0.80)\n",
    "print(galton_train.count())\n",
    "print(galton_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e358a",
   "metadata": {},
   "source": [
    "Ahora usamos nuestro split: Entrenamos con el set de test **galton_test**, y cuando vayamos a ver que tan bueno es el modelo (según MSE, r^2), lo vamos a hacer usando el test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dc8a0c16",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean squared error: 0.002872\nCoeficiente r2: 0.70\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Solo usamos el set de test\n",
    "regr.fit(galton_train[['father','mother','kids','male','female']], galton_train['height'])\n",
    "\n",
    "#ahora usamos el modelo regr pa predecir la altura según el set de test\n",
    "galton_pred = regr.predict(galton_test[['father','mother','kids','male','female']])\n",
    "\n",
    "#y calculamos \n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton_test['height'], galton_pred))\n",
    "\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton_test['height'], galton_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654c535a",
   "metadata": {},
   "source": [
    "Comparemos con el modelo sin el numero de hermanos. Vemos que el MSE ahora es ligeramente inferior, por lo que nos convendría más este modelo. ¿Cómo se compara esto con la situación anterior, cuando no hacíamos **train/test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "fcaef3cd",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean squared error: 0.002871\nCoeficiente r2: 0.70\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Solo usamos el set de test\n",
    "regr.fit(galton_train[['father','mother','male','female']], galton_train['height'])\n",
    "\n",
    "#ahora usamos el modelo regr pa predecir la altura según el set de test\n",
    "galton_pred = regr.predict(galton_test[['father','mother','male','female']])\n",
    "\n",
    "#y calculamos \n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton_test['height'], galton_pred))\n",
    "\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton_test['height'], galton_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bafe08",
   "metadata": {},
   "source": [
    "### K-fold cross validation\n",
    "\n",
    "A veces tenemos mala suerte y el pedazo de test justo se lleva algunos datos muy importantes para la regresión. Para evitar esto, una mejor práctica es hacer variso splits distintos. Esto se conoce como k-fold cross validation, en donde k es el número de grupos. \n",
    "\n",
    "La práctica de k-fold cross validation consiste en: \n",
    "- particionar los datos en k grupos distintos, todos iguales\n",
    "- entrenar k modelos distintos: el modelo j-ésimo usa para entrenar todos los grupos **menos** el grupo j, y usa el grupo j para testear. \n",
    "- los indicadores de cada modelo se agregan en un número. En nuestro caso, vamos a computar el MSE y el r^2, y el total va a ser simplemente el promedio de los k. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd9806",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "Implementa 5-fold cross validation. Prueba con los tres modelos que vimos, y calcula el MSE y el r^2 total para cada uno de ellos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "dd707da6",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "VALORES DE PRIMER MODELO\n",
      "\n",
      "valores de MSE:\n",
      "[0.00303031 0.00331336 0.00316362 0.00286213 0.00291954]\n",
      "Promedio:\n",
      "0.003057790280357916\n",
      "\n",
      "valores de r2:\n",
      "[0.56402935 0.59390326 0.61493263 0.60994901 0.59692882]\n",
      "Promedio:\n",
      "0.5959486145738169\n",
      "\n",
      "\n",
      "VALORES DE SEGUNDO MODELO\n",
      "\n",
      "valores de MSE:\n",
      "[0.00302193 0.00329613 0.00318526 0.00289527 0.00294283]\n",
      "Promedio:\n",
      "0.0030682837174915555\n",
      "\n",
      "valores de R2:\n",
      "[0.56523419 0.59601569 0.6122985  0.60543253 0.59371279]\n",
      "Promedio:\n",
      "0.5945387376756176\n",
      "\n",
      "\n",
      "VALORES DE TERCER MODELO\n",
      "\n",
      "valores de MSE:\n",
      "[0.00566354 0.00336539 0.0033733  0.00349628 0.00469882]\n",
      "Promedio:\n",
      "0.004119467233128952\n",
      "\n",
      "valores de R2:\n",
      "[0.18518583 0.58752647 0.58941039 0.52352611 0.35128107]\n",
      "Promedio:\n",
      "0.44738597474987696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits=5)\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "scores = cross_val_score(regr, galton[['father','mother','kids','male','female']], galton['height'], scoring='neg_mean_squared_error', cv=cv)\n",
    "print(\"\\nVALORES DE PRIMER MODELO\")\n",
    "print(\"\\nvalores de MSE:\")\n",
    "print(abs(scores))\n",
    "print(\"Promedio:\")\n",
    "print(abs(scores).mean())\n",
    "\n",
    "scores = cross_val_score(regr, galton[['father','mother','kids','male','female']], galton['height'], scoring='r2', cv=cv)\n",
    "print(\"\\nvalores de r2:\")\n",
    "print(scores)\n",
    "print(\"Promedio:\")\n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "scores = cross_val_score(regr, galton[['father','mother','male','female']], galton['height'], scoring='neg_mean_squared_error', cv=cv)\n",
    "print(\"\\n\\nVALORES DE SEGUNDO MODELO\")\n",
    "print(\"\\nvalores de MSE:\")\n",
    "print(abs(scores))\n",
    "print(\"Promedio:\")\n",
    "print(abs(scores).mean())\n",
    "\n",
    "\n",
    "scores = cross_val_score(regr, galton[['father','mother','male','female']], galton['height'], scoring='r2', cv=cv)\n",
    "print(\"\\nvalores de R2:\")\n",
    "print(scores)\n",
    "print(\"Promedio:\")\n",
    "print(scores.mean())\n",
    "\n",
    "\n",
    "scores = cross_val_score(regr, galton[['mother','male','female']], galton['height'], scoring='neg_mean_squared_error', cv=cv)\n",
    "print(\"\\n\\nVALORES DE TERCER MODELO\")\n",
    "print(\"\\nvalores de MSE:\")\n",
    "print(abs(scores))\n",
    "print(\"Promedio:\")\n",
    "print(abs(scores).mean())\n",
    "\n",
    "\n",
    "scores = cross_val_score(regr, galton[['mother','male','female']], galton['height'], scoring='r2', cv=cv)\n",
    "print(\"\\nvalores de R2:\")\n",
    "print(scores)\n",
    "print(\"Promedio:\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444af96",
   "metadata": {},
   "source": [
    "### Qué k es mejor usar? \n",
    "\n",
    "Usualmente se trabaja con k = 5 o k = 10, aunque algunas veces tiene sentido hacer que k se el tamaño del dataset (eso se conoce como \"leave one out cross validation\"). Ante la duda, ¡probar con k = 5 y k = 10! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3eb101",
   "metadata": {},
   "source": [
    "### Alternativa 3: Regularizar con LASSO. \n",
    "\n",
    "Otra alternativa para reducir el overfitting es poner una penalización en la función de verosimilitud a la hora de maximizarla. Es decir, vamos a maximizarla, pero vamos a incluir una penalización que depende de la cantidad coeficientes. Esto va a *empujar* a que algunos de esos coeficientes sean 0, cuando la diferencia entre la verosimilitud con/sin esos coeficientes es pequeña. \n",
    "\n",
    "Nosotros solo vamos a ver LASSO, que corresponde a penalizar con el valor absoluto de cada coeficiente: para una regresión sobre entidades con $n$ atributos, la verosimilitud penalizada $\\mathcal P(\\bar x \\mid p)$ se calcula como \n",
    "$$\\mathcal P(\\bar x \\mid p) = \\mathcal L(\\bar x \\mid p) - \\lambda\\sum_{1 \\leq i \\leq n}|\\beta_i|.$$\n",
    "\n",
    "Acá, $\\lambda$ es un parámetro que debe ser proveído por el cientista de datos a cargo de entrenar el modelo (aunque podemos buscar el mejor $\\lambda$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d5feef",
   "metadata": {},
   "source": [
    "Una cosa importante: Como LASSO suma los coeficientes, es importante **estandarizar** nuestros datos. Para eso, tomamos vada valor v y lo transformamos en $(v-\\text{media})/ (\\text{desviacion estandar})$. Nauralmente, no hacemos esto con las variables indicatrices (*male*, *female*) por que esos datos ya vienen estandarizados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2a38f3f3",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     father    mother      kids  male  female    height\n",
       "0  3.751494  1.263788 -0.795431   1.0     0.0  1.797225\n",
       "1  3.751494  1.263788 -0.795431   0.0     1.0  0.680816\n",
       "2  3.751494  1.263788 -0.795431   0.0     1.0  0.624996\n",
       "3  3.751494  1.263788 -0.795431   0.0     1.0  0.624996\n",
       "4  2.537045  1.047058 -0.795431   1.0     0.0  1.880955"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>father</th>\n      <th>mother</th>\n      <th>kids</th>\n      <th>male</th>\n      <th>female</th>\n      <th>height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.751494</td>\n      <td>1.263788</td>\n      <td>-0.795431</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.797225</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.751494</td>\n      <td>1.263788</td>\n      <td>-0.795431</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.680816</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.751494</td>\n      <td>1.263788</td>\n      <td>-0.795431</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.624996</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.751494</td>\n      <td>1.263788</td>\n      <td>-0.795431</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.624996</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.537045</td>\n      <td>1.047058</td>\n      <td>-0.795431</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.880955</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 235
    }
   ],
   "source": [
    "galton_std = galton[['father','mother','kids','male','female','height']].copy()\n",
    "for column in galton_std.columns:\n",
    "   if column != 'male' and column != 'female':\n",
    "        galton_std[column] = (galton_std[column] - galton_std[column].mean()) / galton_std[column].std()\n",
    "\n",
    "galton_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d3ab0f",
   "metadata": {},
   "source": [
    "Recuerda que el significado de estos números en versión estandarizada indica cuantas desviaciones estándar están desde la media (positivo es más a la derecha de la media, negativo es a la izquierda). \n",
    "\n",
    "Entrenemos ahora una regresión con LASSO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "be140a95",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 2.30736471e-01  1.56898288e-01 -0.00000000e+00  1.25207987e+00\n -5.38734282e-16]\n-0.6483487067255514\nMean squared error: 0.375212\nCoeficiente r2: 0.62\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos una regresión con lasso, usamos un alfa de 0.05\n",
    "regr_regularizado = linear_model.Lasso(alpha=0.05)\n",
    "\n",
    "regr_regularizado.fit(galton_std[['father','mother','kids','male','female']], galton_std['height'])\n",
    "\n",
    "print(regr_regularizado.coef_)\n",
    "print(regr_regularizado.intercept_)\n",
    "\n",
    "regr_regularizado.predict(para_predecir)\n",
    "\n",
    "#Ahora predecimos un poco y calculamos el MSE y r^2\n",
    "galton_pred = regr_regularizado.predict(galton_std[['father','mother','kids','male','female']])\n",
    "\n",
    "#y calculamos \n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton_std['height'], galton_pred))\n",
    "\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton_std['height'], galton_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb7f9a",
   "metadata": {},
   "source": [
    "Fijate como ha desaparecido el coeficiente correspondiente a *kids*, y como casi desaparece el de *female* (este es superfluo, basta con uno entre male/female. Es por este motivo que LASSO tiende a regularizar de forma práctica: los valores de los coeficientes van bajando hasta transformarse en 0. \n",
    "\n",
    "Lo otro que es interesante: fíjate como ha subido el coeficiente r^2. El MSE no es comparable con el de la regresión que no está estandarizada. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a1e3b6",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "Busca el mejor $\\lambda$ para usar LASSO. PAra ver cuál modelo es mejor, usa 5-fold cross validation, y selecciona los modelos que tengan el menor MSE (o el menor r^2, como prefieras). "
   ]
  },
  {
   "source": [
    "#### Resultado\n",
    "Se utilizará LassoCV, una implementacion de cross validation par Lasso que ya viene en sklearn. Asi, definimos el 5-fold con KFold y generamos la regresion con los valores estandarizados de galton. LassoCV calcula por si solo el valor de alpha mas adecuado, pero tambien se calculara basado en el menor valor de MSE."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.00035670332276015697"
      ]
     },
     "metadata": {},
     "execution_count": 237
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from numpy import column_stack\n",
    "kf = KFold(n_splits=5)  \n",
    "regr = LassoCV(cv=kf).fit(galton_std[['father','mother','kids','male','female']], galton_std['height'])\n",
    "regr.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "93763909",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      alpha       MSE\n",
       "0  0.356703  1.038333\n",
       "1  0.332663  0.980701\n",
       "2  0.310242  0.922820\n",
       "3  0.289333  0.871120\n",
       "4  0.269833  0.826205"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alpha</th>\n      <th>MSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.356703</td>\n      <td>1.038333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.332663</td>\n      <td>0.980701</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.310242</td>\n      <td>0.922820</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.289333</td>\n      <td>0.871120</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.269833</td>\n      <td>0.826205</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 238
    }
   ],
   "source": [
    "result = pd.DataFrame(regr.alphas_,columns=[\"alpha\"])\n",
    "result[\"MSE\"] = regr.mse_path_.mean(axis=1).tolist()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.00035670332276015697\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "alpha    0.000357\n",
       "MSE      0.369232\n",
       "Name: 99, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 239
    }
   ],
   "source": [
    "best_alpha = result.iloc[result['MSE'].idxmin()]\n",
    "print(best_alpha[\"alpha\"])\n",
    "best_alpha"
   ]
  },
  {
   "source": [
    "Como podemos ver, tanto LassoCV como el calculo de los MSE da el mismo resultado de mejor valor para alpha."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "02de5609ef162b6bcc51dd429fd31b9a1f163c414526741362218fd7f2e354ad"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}